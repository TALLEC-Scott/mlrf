{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EPITA 2022 MLRF practice_01-04_color-histogram v2022-03-30_095240 by Joseph CHAZALON\n",
    "\n",
    "<div style=\"overflow: auto; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"Creative Commons License\" src='img/CC-BY-4.0.png' style='float: left; margin-right: 20px'>\n",
    "    \n",
    "This work is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice 1 part 4: (Indexed) color histograms as global descriptors\n",
    "\n",
    "The principle is very simple and illustrated below: from a set of pixels we count how many times each color appears, and we build an histogram of the frequencies (as opposed to raw counts, because we normalize the values) of occurrences of colors.\n",
    "\n",
    "Here are some examples of the histograms we can compute from some bubbles:\n",
    "![hist1](img/hist1.png)\n",
    "![hist2](img/hist2.png)\n",
    "![hist3](img/hist3.png)\n",
    "\n",
    "Using such descriptors, we can very easily group similar bubbles with a reasonable confidence.\n",
    "\n",
    "This part contains the following steps:\n",
    "1. Color quantization: reduce the colors of the bubbles.\n",
    "2. Compute the color histogram of each bubble.\n",
    "3. Compute the distance matrix between each bubble, using its color histogram.\n",
    "4. Visualize the bubbles in an interesting way using hierarchical clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Color quantization\n",
    "It is hard to compare the full RGB histogram of an image (a bubble) with the histogram of another, so we will first **reduce the number of colors** used to represent each image.\n",
    "\n",
    "\n",
    "Color quantization is a practical application of [vector quantization](https://en.wikipedia.org/wiki/Vector_quantization) where each color is replaced by the closest color in a pre-defined palette.\n",
    "\n",
    "\n",
    "We have two options here:\n",
    "1. build a palette manually\n",
    "2. use a clustering technique to build it automatically\n",
    "\n",
    "We will use **K-Means clustering** to discover a reduced set of representative colors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: solid; border-color: red; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"stop\" src='img/stop.png' style='float: left; margin-right: 20px'>\n",
    "    \n",
    "**If you do not manage to build the palette automatically, then build your codebook manually and convert the color of the images using [`scipy.cluster.vq.vq`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.vq.vq.html).**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Sample some pixels\n",
    "Because K-Means is a costly algorithm, we will first sample our pixels (viewing them as plain 3-dimensional vectors) to avoid filling up our memory during KMeans fitting.\n",
    "\n",
    "We will use the base image to facilitate the sampling, because otherwise we would have to select pixels from every bubble image and merge the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**Use the large (200 DPI) poster image WITH ITS MASK to sample some pixels. 5000 is a good number of samples.**\n",
    "\n",
    "*Tips:*\n",
    "- The code for loading the image is provided below to save you time.\n",
    "- `poster[poster_mask]` returns a set of valid pixels.\n",
    "- You can use [`np.random.choice`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html) to select **random pixems** from the set of pixels belonging to the bubbles.\n",
    "- The overall idea is the run 2 \"select\" operations on the original image: 1) select the pixels which belong to bubbles (i.e. not in the background) and 2) select some random pixels among these.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deactivate buggy jupyter completion\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "PATH_TO_RESOURCES = \".\"  # FIXME set this to the path of the twinit resource directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the base image and its mask.\n",
    "poster = cv2.imread(os.path.join(PATH_TO_RESOURCES, \"twin_it_200dpi.png\"))\n",
    "# let us convert the poster from BGR to RGB for what follows\n",
    "# we will work with RGB images\n",
    "poster = cv2.cvtColor(poster, cv2.COLOR_BGR2RGB)\n",
    "# Read the mask image\n",
    "poster_mask = cv2.imread(os.path.join(PATH_TO_RESOURCES, \"mask_bubbles.png\"))[..., 0] > 0\n",
    "# Check the shape and data type of our arrays\n",
    "poster.shape, poster.dtype, poster_mask.shape, poster_mask.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"warning\" src='img/warning.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**WARNING: All our images should be in RGB format in this session! Convert them when loading them to avoid mistakes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(poster)  # no need for `cv2.cvtColor` because we already have an RGB image\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(poster_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO now sample 5000 pixels from the image\n",
    "sample_pixels = np.array([])  # FIXME\n",
    "# ...\n",
    "sample_pixels.shape, sample_pixels.dtype\n",
    "# The last line should return\n",
    "# ((5000, 3), dtype('uint8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. K-Means clustering stage 1/2: fitting\n",
    "We are now ready to perform K-Means clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**Use K-Means clustering to compute the color palette. Use a small value like 7 for the number of target colors.**\n",
    "\n",
    "Tip:\n",
    "- Set the `random_state` parameter to some fixed value to ensure the reproducibility of your results.\n",
    "- Use the `fit` method to compute cluster centers.\n",
    "- The cluster centers will be available with `kmeans.cluster_centers_`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"warning\" src='img/warning.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**WARNING: K-Means is a RAM-hungry algorithm. Save your work regularly (and start now)!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compute the new color palette\n",
    "kmeans = None # FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. K-Means clustering stage 2/2: projection\n",
    "The [`KMeans` class](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) provided by scikit-learn has two methods for transforming our data:\n",
    "- `transform`\n",
    "- `predict`\n",
    "\n",
    "**Make sure you understand the difference between those two functions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**Use the `KMeans` object and super fancy Numpy indexing to create a new image where the color of each pixel is the color of the closest cluster to the original pixel color.**\n",
    "\n",
    "Tip:\n",
    "- Do not forget to mask the background of the image during prediction (because we did not train the predictor on them).\n",
    "- Start by producing a new image with cluster labels instead of color values.\n",
    "- Then create a color lookup table (LUT) using cluster centers (make sure to use `np.uint8` values to avoid issues with later conversion).\n",
    "- Finally use Numpy advanced indexing to apply the LUT to the image with cluster labels.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some extra help about the LUT thing:\n",
    "my_LUT = np.array([(\"a\", \"b\"),  # \"cluster\" 0\n",
    "                   (\"c\", \"d\")]) # \"cluster\" 1\n",
    "my_label_image = np.array([[0,1,0,1,1]])\n",
    "my_LUT[my_label_image]\n",
    "# The result contains values from `my_LUT` and has the shape of `my_label_image`. Simply beautiful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Create a label map (for each pixel inside a bubble, get the id of the closest cluster)\n",
    "label_map = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (we give you the code for this, try to understand it)\n",
    "# Create and show the LUT and its colors\n",
    "color_lut = np.uint8(kmeans.cluster_centers_)\n",
    "plt.bar(np.arange(len(color_lut)), \n",
    "         np.ones(len(color_lut)), \n",
    "         color=color_lut/255)\n",
    "color_lut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Now create a recolored image `test_recolored` containing only indexed colors (ie. in the LUT) using:\n",
    "# - the original image `poster`, \n",
    "# - the mask `poster_mask` of pixels belonging to bubbles (and therefore not to the background)\n",
    "# - the LUT `color_lut`\n",
    "# TIP: start by filling your image with white color.\n",
    "test_recolored = np.zeros_like(poster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us display zoomed portions of the images\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(poster[:1000,:1000])\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Original\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(test_recolored[:1000,:1000])\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Recolored\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**Does this look correct?**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(you can write some observations here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**Save the image and compare its size with the original one. Make sure you use the right color space when saving!**\n",
    "\n",
    "Tips:\n",
    "\n",
    "- If saving the RGB image with OpenCV `cv2.imwrite()`, do not forget it expects a BGR image! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO save the image and compare the sizes\n",
    "cv2.imwrite(\"/tmp/recolored.png\", test_recolored)  # FIXME make sure the exported image is in BGR format here!\n",
    "# Let us use some notebook magic to check the size of the image\n",
    "!du -h /tmp/recolored.png\n",
    "!du -h $PATH_TO_RESOURCES/twin_it_200dpi.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Load and convert all the bubbles\n",
    "We can now load and convert all the bubbles. We need to:\n",
    "1. load them\n",
    "2. convert them to the same color space as use during training (RGB here)\n",
    "3. project their colors using the previous method\n",
    "\n",
    "We will need to ignore the area where all the pixels are black `(0,0,0)`, because they do not belong to the bubble and it may change their value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**First define a function to compute the mask of a bubble.**\n",
    "\n",
    "Tip:\n",
    "- It is a boolean image where $(x,y)$ is `True` as soon as the value of any channel of the original image, at $(x,y)$ is $> 0$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO define a function to compute the mask of a bubble\n",
    "def bubble2mask(bubble):\n",
    "    return np.zeros_like(bubble, dtype=np.bool) # FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**Now load all the bubbles and convert them to RGB (or any color space your choosed).**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Jupyter magic to help you\n",
    "bubble_files = !ls $PATH_TO_RESOURCES/bubbles_200dpi/b*.png  | sort\n",
    "bubble_files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO load all the bubbles and convert them to RGB\n",
    "# `bubbles` is a list of np.array elements (bubble images in RGB format)\n",
    "bubbles = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**And reduce the color of all bubbles.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO reduce the color of all bubbles\n",
    "# This is exactly what we did for the full poster, but applied to each bubble AND keeping background as black.\n",
    "bubbles_quant = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us display the images\n",
    "plt.figure(figsize=(8,16))\n",
    "for ii in range(10):\n",
    "    plt.subplot(10,2,1+2*ii)\n",
    "    plt.imshow(bubbles[ii])\n",
    "    plt.axis(\"off\")\n",
    "    if ii == 0:\n",
    "        plt.title(\"Original\")\n",
    "    plt.subplot(10,2,2+2*ii)\n",
    "    plt.imshow(bubbles_quant[ii])\n",
    "    plt.axis(\"off\")\n",
    "    if ii == 0:\n",
    "        plt.title(\"Recolored\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute the color histograms\n",
    "To compute the color histogram of a bubble, we do not need to recolorize it, we just need to compute its \"label map\" to count the number of pixel belonging to each cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**Compute the color histogram for each bubble. Use [`np.bincount`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.bincount.html#numpy.bincount) to count the number of number of occurence of each cluster label. Do not forget to normalize the histogram using the number of non-zero values in the mask with [`np.count_nonzero`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.count_nonzero.html).**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compute the color histogram for each bubble (number of pixel in each cluster) then normalize it.\n",
    "# `color_histograms` is a list of np.array, \n",
    "# each element being the histogram corresponding to a bubble in `bubbles`.\n",
    "color_histograms = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some color histograms with colors!\n",
    "colors_for_bars = color_lut/255  # matplotlib colors are RGB values scaled to [0,1]\n",
    "for ii in range(5):\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(bubbles[ii])\n",
    "    plt.axis('off'); plt.title(\"Original\")\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(bubbles_quant[ii])\n",
    "    plt.axis('off'); plt.title(\"Recolored\")\n",
    "    plt.subplot(1,3,3, aspect=len(color_histograms[0]))\n",
    "    plt.ylim(0, 1)\n",
    "    plt.bar(range(len(color_histograms[ii])), \n",
    "            color_histograms[ii]/color_histograms[ii].max(), \n",
    "            color=colors_for_bars)\n",
    "    plt.xticks([]); plt.title(\"Histogram\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute the distance matrix\n",
    "Because color histograms are **very compact**, it is **very fast** to compute the distance matrix (even if the complexity is $O(n^2)$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**Compute the distance matrix between each pair of bubbles. Use an appropriate distance from [`scipy.spatial.distance`](https://docs.scipy.org/doc/scipy/reference/spatial.distance.html).**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compute the distance matrix between each pair of bubbles\n",
    "dist_mat = np.ones((len(bubbles), len(bubbles)))  # distances will be between 0 (closest) and 1 (farthest)\n",
    "# for... dist_mat[i,j] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct the diagonal to avoid getting the same result over and over: we set the distance of one element against itself to the maximum distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat[np.diag_indices_from(dist_mat)] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**Display the best matches for some (all?) bubbles, ie the bubbles which are the closest to a given one. Use `np.argsort` along the appropriate axis to get the indices of the closest elements along each line.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "# Compute the indices of elements with smallest distance to each bubble (ie. in a matrix row)\n",
    "# `idx_of_best_matches_per_row` is a 2D np.array: \n",
    "# for each row, the columns indicate the indices of the elements in `dist_mat` to sort the row (ascending order)\n",
    "idx_of_best_matches_per_row = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the best matches for some bubbles\n",
    "max_res = 5\n",
    "interesting_bubble_ids = [0, 1, 35, 36, 43, 44, 49, 50, 91, 92, 105, 106]\n",
    "\n",
    "for ii in interesting_bubble_ids:\n",
    "    plt.figure(figsize=(12,8))\n",
    "    columns = max_res + 1\n",
    "    plt.subplot(1, columns, 1)\n",
    "    plt.imshow(bubbles[ii])\n",
    "    plt.axis(\"off\"); plt.title(\"Bubble %d\"%(ii,))\n",
    "    for jj in range(max_res):\n",
    "        bb_idx = idx_of_best_matches_per_row[ii, jj]  # Read the id of each best match for current bubble\n",
    "        plt.subplot(1, columns, jj+2)\n",
    "        plt.imshow(bubbles[bb_idx])\n",
    "        plt.axis(\"off\"); plt.title(\"b%d@%.3f\" % (bb_idx, dist_mat[ii, bb_idx])) # display bubble id and dist.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**Write some notes about the advantages and the limitations of the color histogram approach.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO write some notes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hierarchical clustering and dendrograms\n",
    "Instead of computing a distance matrix, it is also possible to aggregate the elements starting by the closest one, then iterating. The trick is to be able to compute the distance between a cluster and another cluster, and a simple solution is to average the descriptor of two clusters to form the descriptor of a new parent cluster.\n",
    "\n",
    "The code below does all this work and produces a dendrogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "**Call the functions (2nd and 3rd cells below) appropriately to generate a beautiful image.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/jesolem/PCV/blob/master/PCV/clustering/hcluster.py\n",
    "# licensed under the BSD 2-Clause \"Simplified\" License\n",
    "from itertools import combinations\n",
    "\n",
    "class ClusterNode(object):\n",
    "    def __init__(self,vec,left,right,distance=0.0,count=1):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.vec = vec\n",
    "        self.distance = distance\n",
    "        self.count = count # only used for weighted average\n",
    "\n",
    "    def extract_clusters(self,dist):\n",
    "        \"\"\" Extract list of sub-tree clusters from \n",
    "            hcluster tree with distance<dist. \"\"\"\n",
    "        if self.distance < dist:\n",
    "            return [self]\n",
    "        return self.left.extract_clusters(dist) + self.right.extract_clusters(dist)\n",
    "\n",
    "    def get_cluster_elements(self):\n",
    "        \"\"\"    Return ids for elements in a cluster sub-tree. \"\"\"\n",
    "        return self.left.get_cluster_elements() + self.right.get_cluster_elements()\n",
    "\n",
    "    def get_height(self):\n",
    "        \"\"\"    Return the height of a node, \n",
    "            height is sum of each branch. \"\"\"\n",
    "        return self.left.get_height() + self.right.get_height()\n",
    "\n",
    "    def get_depth(self):\n",
    "        \"\"\"    Return the depth of a node, depth is \n",
    "            max of each child plus own distance. \"\"\"\n",
    "        return max(self.left.get_depth(), self.right.get_depth()) + self.distance\n",
    "\n",
    "    def draw(self,draw,x,y,s,imlist,im):\n",
    "        \"\"\"    Draw nodes recursively with image \n",
    "            thumbnails for leaf nodes. \"\"\"\n",
    "        h1 = int(self.left.get_height()*60 / 2)\n",
    "        h2 = int(self.right.get_height()*60 /2)\n",
    "        top = y-(h1+h2)\n",
    "        bottom = y+(h1+h2)\n",
    "        \n",
    "        # vertical line to children\n",
    "        cv2.line(draw, (int(top+h1), int(x)) , (int(bottom-h2),int(x)), (0,0,0))\n",
    "        \n",
    "        # horizontal lines \n",
    "        ll = self.distance*s\n",
    "        cv2.line(draw, (int(top+h1),int(x)) , (int(top+h1), int(x+ll)), (0,0,0))\n",
    "        cv2.line(draw, (int(bottom-h2), int(x)) , (int(bottom-h2), int(x+ll)), (0,0,0))\n",
    "        \n",
    "        # draw left and right child nodes recursively    \n",
    "        self.left.draw(draw,x+ll,top+h1,s,imlist,im)\n",
    "        self.right.draw(draw,x+ll,bottom-h2,s,imlist,im)\n",
    "    \n",
    "\n",
    "class ClusterLeafNode(object):\n",
    "    def __init__(self,vec,id):\n",
    "        self.vec = vec\n",
    "        self.id = id\n",
    "\n",
    "    def extract_clusters(self,dist):\n",
    "        return [self] \n",
    "\n",
    "    def get_cluster_elements(self):\n",
    "        return [self.id]\n",
    "\n",
    "    def get_height(self):\n",
    "        return 1\n",
    "\n",
    "    def get_depth(self):\n",
    "        return 0\n",
    "    \n",
    "    def draw(self,draw,x,y,s,imlist,im):\n",
    "        nodeim = cv2.resize(imlist[self.id], (60,60))\n",
    "        ns = nodeim.shape\n",
    "        im[int(x):int(x+ns[0]), int(y-ns[1]//2):int(y+ns[1]-ns[1]//2), ...] = nodeim\n",
    "\n",
    "\n",
    "def hcluster(features, distfcn):\n",
    "    \"\"\"\n",
    "    Cluster the rows of features using hierarchical clustering.\n",
    "    \n",
    "    `features`: square matrix of features\n",
    "    `distfcn`: distance function to compare features (feature x feature -> float)\n",
    "    \"\"\"\n",
    "    \n",
    "    # cache of distance calculations\n",
    "    distances = {}\n",
    "    \n",
    "    # initialize with each row as a cluster \n",
    "    node = [ClusterLeafNode(f,id=i) for i,f in enumerate(features)]\n",
    "    \n",
    "    while len(node)>1:\n",
    "        closest = float('Inf')\n",
    "        \n",
    "        # loop through every pair looking for the smallest distance\n",
    "        for ni,nj in combinations(node,2):\n",
    "            if (ni,nj) not in distances: \n",
    "                distances[ni,nj] = distfcn(ni.vec,nj.vec)\n",
    "                \n",
    "            d = distances[ni,nj]\n",
    "            if d<closest:\n",
    "                closest = d \n",
    "                lowestpair = (ni,nj)\n",
    "        ni,nj = lowestpair\n",
    "        \n",
    "        # average the two clusters\n",
    "        new_vec = (ni.vec + nj.vec) / 2.0\n",
    "        \n",
    "        # create new node\n",
    "        new_node = ClusterNode(new_vec,left=ni,right=nj,distance=closest)\n",
    "        node.remove(ni)\n",
    "        node.remove(nj)\n",
    "        node.append(new_node)\n",
    "    \n",
    "    return node[0]\n",
    "\n",
    " \n",
    "def draw_dendrogram(node, imlist, filename='dendrogram.jpg'):\n",
    "    \"\"\"\n",
    "    Draw a cluster dendrogram and save to a file. \n",
    "    \n",
    "    `node`: result of the `hcluster` function\n",
    "    `imlist`: list of BGR images for each element\n",
    "    `filename`: path to output file\n",
    "    \"\"\"\n",
    "    # height and width\n",
    "    cols = node.get_height()*60\n",
    "    rows = 1200\n",
    "\n",
    "    # scale factor for distances to fit image width\n",
    "    s = float(rows-150)/node.get_depth()\n",
    "    \n",
    "    # create image and draw object\n",
    "    im = np.full((rows,cols, 3), 255, dtype=np.uint8)\n",
    "    draw = im\n",
    "    \n",
    "    # initial line for start of tree \n",
    "    cv2.line(draw, (cols//2, 0),(cols//2, 60), (0,0,0))\n",
    "    \n",
    "    # draw the nodes recursively\n",
    "    node.draw(draw,60,(cols/2),s,imlist,im)\n",
    "    cv2.imwrite(filename, draw)\n",
    "    print(\"Wrote '%s'.\" % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO generate the clusters using the features you computed, and a distance function of your choice\n",
    "cluster = None # hcluster(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubbles_bgr = [cv2.cvtColor(bb, cv2.COLOR_RGB2BGR) for bb in bubbles]\n",
    "draw_dendrogram(cluster, bubbles_bgr, \"my_dendrogram.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job done!\n",
    "Do not forget to submit your notebooks (and maybe a scaled version of your dendrogram)!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
